{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 05: Building Convolution and Pooling Layers from Scratch  (Example Solution)\n",
    "---\n",
    "\n",
    "**Due Date:** Tuesday 06/18/2025 (by midnight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill these in before submitting, just in case I accidentally mix up file names while grading**:\n",
    "\n",
    "Name: Jane Hacker\n",
    "\n",
    "CWID-5: (Last 5 digits of cwid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction \n",
    "\n",
    "Welcome to our first assignment for the classes Computer Vision and Convolutional Networks section.  In this assignment you are going to implement functions to perform the convolutional and pooling layer operations in numpy.  Each function you will implement will have detailed instructions that will walk you through the steps needed:\n",
    "\n",
    "- Convolution functions, including:\n",
    "    - Zero Padding\n",
    "    - Convolve window \n",
    "    - Convolution forward\n",
    "    - Convolution backward (TODO)\n",
    "- Pooling functions, including:\n",
    "    - Pooling forward\n",
    "    - Create mask \n",
    "    - Distribute value\n",
    "    - Pooling backward (TODO)\n",
    "    \n",
    "This notebook will ask you to implement these functions from scratch in `numpy`. \n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "- The forward pass convolution and pooling functions could be vectorized.  However for this assignment, the purpose is to learn conceptually how the\n",
    "  convolution and pooling operations work.  So you should use for loop iterations as described for these function.  We leave it as an exercise for the\n",
    "  student to think how you might go about fully vectorizing the convolution and pooling function.\n",
    "- As with the previous assignment, you will need to create the function declarations asked for\n",
    "  in `src/assg_tasks.py`.  Make sure you use\n",
    "  [Python Docstrings](https://www.geeksforgeeks.org/python-docstrings/) and are generally\n",
    "  following [Pep8 Python Style Guide](https://peps.python.org/pep-0008/) for your code.\n",
    "\n",
    "**You will learn:**\n",
    "\n",
    "- How to figure out the resulting size of an output height x width shape for a convolution\n",
    "  or maxpooling operation given the stride size, padding and kernel sizes being used.\n",
    "- How convolutions are computed at the basic level for a convolution layer.\n",
    "- How max pooling and average pooling works and is implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "The following imports should be all of the backages that you will need for this assignment.\n",
    "We are using the Keras API in this assignment and in future assignments, so the `tensorflow` and `keras` modules\n",
    "you need are now available in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 00:43:38.183989: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-12 00:43:38.188422: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-12 00:43:38.197777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749689018.212043    2969 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749689018.216167    2969 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749689018.229533    2969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749689018.229556    2969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749689018.229558    2969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749689018.229559    2969 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-12 00:43:38.233620: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# assignment wide imports go here, usually all of your imports for noteboosk should\n",
    "# be put up at the top here, if they were not given to you at the start of the assignment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following ipython magic will reload changed file/modules.\n",
    "# So when editing function in source code modules, you should\n",
    "# be able to just rerun the cell, not restart the whole kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports of the function you will write have been commented out here this time.  You will need to uncomment\n",
    "the imports once you declare and write your functions here, and also in the `src/test_assg_tasks.py` file to\n",
    "run the unit tests on your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions/moduls from this project.  We manually set the\n",
    "# PYTHONPATH to append the location to search for this assignments\n",
    "# functions to just ensure the imports are found\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# assignment function imports for doctests and github autograding\n",
    "# these are required for assignment autograding\n",
    "from assg_utils import run_unittests, run_doctests\n",
    "#from assg_tasks import calc_new_height_width\n",
    "#from assg_tasks import pool_forward\n",
    "#from assg_tasks import zero_pad\n",
    "#from assg_tasks import conv_single_step\n",
    "#from assg_tasks import conv_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set notebook wide defaults for small image plots\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Pooling Layer Implementation\n",
    "\n",
    "We will start with the pooling layer as its implementation is similar to but slightly\n",
    "easier than the convolution layer.  But first, a utility function that will be used for both\n",
    "types of layers to determine what the output height and width will be as a result\n",
    "of the layer performing its operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.1: Compute Output height x width of Sliding conv/pool Window\n",
    "\n",
    "A useful function will be to compute what the new output height and width\n",
    "of a convolution or pooling operation will be given the input height, width, the kernel_size \n",
    "of the window, and the stride and padding values.\n",
    "\n",
    "The following is a simple animation of the sliding window for a convolution:\n",
    "\n",
    "<img src=\"../figures/single_step_convolution_animation.gif\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "**Sliding Window**: with a `kernel_size` of 3x3 and a `stride` of 1 (stride = amount you move the window each time you slide)\n",
    "\n",
    "For example, in the animation above there is no padding so `pad = 0` and and\n",
    "the stride step is 1 so `stride = 1`.  In the animation, the input activation has\n",
    "a `height x width` of `5x5`.  That means that the new `height x width` ends up being\n",
    "`3x3` for the output after sliding the kernel window over the input.\n",
    "\n",
    "But if we add `pad = 1` then the new `height x width` would be preserved and would be\n",
    "`5x5`.  If we did a `pad = 2` then the new ouput would increase to `6x6`.\n",
    "\n",
    "But also we have to take into account stride.  So for example with no padding\n",
    "and a `stride = 2` we would only be able to slide 2 times horizontally and vertically,\n",
    "resulting in a `2x2` output.\n",
    "\n",
    "You could probably work out from first principles a formula for what the resulting new width and new height\n",
    "would be given an input `width x height`, the window `kernel_size` and stride and padding.  But to save a little time, the\n",
    "following expressions will calculate these.  We use the following variables in these formula:\n",
    "\n",
    "- `height` and `width` are the height and width of the input activation that we are convolving over.\n",
    "- `kernel_size` is the size of the convolution kernel window.  We will always use a square kernel,\n",
    "  so for example when `kernel_size` is 3, we are sliding a 3x3 window over the input for\n",
    "  the convolution.\n",
    "- `strice` and `pad` are the stride size (minimum 1) and the amount of padding added (can be 0).\n",
    "\n",
    "So in that case the `new_height` and `new_width` would be:\n",
    "\n",
    "\\begin{equation}\n",
    "new\\_height = \\left\\lfloor \\frac{height - kernel\\_size + 2 \\times pad}{stride} \\right\\rfloor + 1\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "new\\_width = \\left\\lfloor \\frac{width - kernel\\_size + 2 \\times pad}{stride} \\right\\rfloor + 1\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\left\\lfloor x \\right\\rfloor$ represents the mathematical `floor()` function, though\n",
    "this is only to ensure that the result is an integer.  You could cast to an int, or in\n",
    "python3 you could use the `//` which forces integer division in an expression.\n",
    "\n",
    "**Task**: Write a utility function named `cacl_new_height_width()`.  This function should take\n",
    "the following parameters in this order:\n",
    "\n",
    "- `height` and `width` of the input activation\n",
    "- the `kernel_size` of the sliding window\n",
    "- `stride` and `pad` settings\n",
    "\n",
    "It should calculate and return the \n",
    "resulting `new_height` and `new_width` as a tuple, which are required to be `int` types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTED function calc_new_height_width\n",
    "# uncomment when ready to run the unit tests for function, and uncomment below to test expected results\n",
    "#run_unittests(['test_calc_new_height_width'])\n",
    "\n",
    "# a simple case, the above 5x5 input with kernel_size 3, stride 1 and 0 padding\n",
    "height = width = 5\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "pad = 0\n",
    "#new_height, new_width = calc_new_height_width(height, width, kernel_size, stride, pad)\n",
    "#print(new_height, new_width)\n",
    "\n",
    "# a bit more complex, 12x21 input, kernel_size 4, stride 2 and pad 2\n",
    "height = 12\n",
    "width = 21\n",
    "kernel_size = 4\n",
    "stride = 2\n",
    "pad = 2\n",
    "#new_height, new_width = calc_new_height_width(height, width, kernel_size, stride, pad)\n",
    "#print(new_height, new_width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Result**:  You should get the following output for the two cases shown\n",
    "\n",
    "```\n",
    "3 3\n",
    "7 11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.2: Forward Pooling\n",
    "\n",
    "The pooling layer downsamples.  In other words it reduces the height and width of the input.\n",
    "It helps reduce computation, as well as helps make feature detectors more invariant to its\n",
    "position in the input. The two types of pooling layers are: \n",
    "\n",
    "- Max-pooling layer: slides an (`kernel_size` x `kernel_size`) window over the input and stores the max value of the window in the output.\n",
    "\n",
    "- Average-pooling layer: slides an (`kernel_size` x `kernel_size`) window over the input and stores the average value of the window in the output.\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"../figures/max_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"../figures/average_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>\n",
    "\n",
    "**Task**: Implement a function named `pool_forward()`.\n",
    "\n",
    "This function will take in the following input parameters\n",
    "\n",
    "- `A`: The input activation into this pooling layer.  This is a numpy array\n",
    "       of shape `(m, height, width, channels)` which has `m` input samples, each a\n",
    "       `(height, width, channels)` shaped 3D tensor.\n",
    "- `kernel_size`: The kernel size to use for the pooling function.  For example\n",
    "       a kernel size of 2 will use a 2x2 window and will downsample 2x,\n",
    "       a kernel size of 3 by 3x\n",
    "- `mode`: A string, either 'max' or 'avg', should default to 'max' if not\n",
    "       specified.\n",
    "\n",
    "This function returns the downsampled/pooled result of processing the\n",
    "input activations `A`.  \n",
    "\n",
    "**Algorithm Description**\n",
    "\n",
    "Implementing pooling can be done in the following way:\n",
    "\n",
    "1. Query the input activations `A` to find out the number of\n",
    "   samples `m`, `height`, `width` and `channels` of the incoming activations.\n",
    "2. Calculate the `new_height` and `new_width` that will result.  You are required to\n",
    "   reuse your previous `calc_new_height_width()`.  The idea is that there is\n",
    "   no padding in pooling, so `pad = 0`.  And you are striding by the\n",
    "   `kernel_size` each time to have nonoverlapping windows.\n",
    "3. Initialize an empty or 0 array to hold the returned pooled results, for example\n",
    "   calling it `Z`.  You know the resulting shape after pooling\n",
    "   will be `(m, new_height, new_width, channels)`\n",
    "4. You will need a 4 deep nested for loop over samples, new_height, new_width,\n",
    "   channels.\n",
    "```python\n",
    "for s in range(m):\n",
    "    for h in range(new_height):\n",
    "        # you need to calculate the start and end for dimension 1 height slice\n",
    "        for w in range(new_width):\n",
    "            # you need to calculate the start and end for dimension 2 height slice\n",
    "            for c in range(channels):\n",
    "                # you need the window from A[s, hstart:hend, vstart:vend, c] to pool\n",
    "                # get the max or average of the window slice from A and save in Z[s, h, w, c]\n",
    "                \n",
    "```\n",
    "The only tricky part in your loop is, given the h and w index for the pooled output, you have to\n",
    "calculate the start and end index for your input activations.  Just as an example, if the\n",
    "`kernel_size` for the window is 3, then when `h=0` and `w=0` the first time in the loop you\n",
    "need the `A[s, 0:3, 0:3, c]` window slice to average or find maximum of.  When `w` increments to 1,\n",
    "you then need the window slice `A[s, 0:3, 3:6, c]`, etc.  Each increment of h and w slides the\n",
    "start and end index of the slice you need by the kernel size of the window being used for the pooling.\n",
    "\n",
    "5. Return the filled in `Z` array that is the result of pooling using your sliding window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pooling:\n",
      "A sample 2 channel 2\n",
      "[[ 1  1 -4 -1]\n",
      " [ 4  4 -1  3]\n",
      " [ 0  3 -4 -2]\n",
      " [-2 -1 -5 -2]]\n",
      "\n",
      "Average pooling:\n",
      "A sample 2 channel 2\n",
      "[[ 1  1 -4 -1]\n",
      " [ 4  4 -1  3]\n",
      " [ 0  3 -4 -2]\n",
      " [-2 -1 -5 -2]]\n"
     ]
    }
   ],
   "source": [
    "### TESTED function pool_forward\n",
    "# uncomment when ready to run the unit tests for function, and uncomment below to test expected results\n",
    "#run_unittests(['test_pool_forward'])\n",
    "np.random.seed(1)\n",
    "A = np.random.randint(-5, 5, size=(3, 4, 4, 4))\n",
    "\n",
    "print('Max pooling:')\n",
    "kernel_size = 2\n",
    "#Z = pool_forward(A, kernel_size, mode='max')\n",
    "#print('Z.shape: ', Z.shape)\n",
    "# sample 2 channel 2 input\n",
    "print('A sample 2 channel 2')\n",
    "print(A[2, :, :, 2])\n",
    "#print('Z sample 2 channel 2')\n",
    "#print(Z[2, :, :, 2])\n",
    "\n",
    "print('\\nAverage pooling:')\n",
    "kernel_size = 2\n",
    "#Z = pool_forward(A, kernel_size, mode='avg')\n",
    "#print('Z.shape: ', Z.shape)\n",
    "# sample 2 channel 2 input\n",
    "print('A sample 2 channel 2')\n",
    "print(A[2, :, :, 2])\n",
    "#print('Z sample 2 channel 2')\n",
    "#print(Z[2, :, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: For the given seed you should get the\n",
    "following output for your max and average pooling.\n",
    "\n",
    "```\n",
    "Max pooling:\n",
    "Z.shape:  (3, 2, 2, 4)\n",
    "A sample 2 channel 2\n",
    "[[ 1  1 -4 -1]\n",
    " [ 4  4 -1  3]\n",
    " [ 0  3 -4 -2]\n",
    " [-2 -1 -5 -2]]\n",
    "Z sample 2 channel 2\n",
    "[[ 4.  3.]\n",
    " [ 3. -2.]]\n",
    "\n",
    "Average pooling:\n",
    "Z.shape:  (3, 2, 2, 4)\n",
    "A sample 2 channel 2\n",
    "[[ 1  1 -4 -1]\n",
    " [ 4  4 -1  3]\n",
    " [ 0  3 -4 -2]\n",
    " [-2 -1 -5 -2]]\n",
    "Z sample 2 channel 2\n",
    "[[ 2.5  -0.75]\n",
    " [ 0.   -3.25]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Convolutional Layer Implementation\n",
    "\n",
    "Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below. \n",
    "\n",
    "<img src=\"../figures/conv_nn.png\" style=\"width:350px;height:200px;\">\n",
    "\n",
    "In this part, you will build every step of the convolution layer. You will first implement two helper functions: one for zero padding and the other for computing the convolution function itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.1: Zero-Padding\n",
    "\n",
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "<img src=\"../figures/zero_padding.png\" style=\"width:600px;height:400px;\">\n",
    "\n",
    " **Zero-Padding** Image (3 channels, RGB) with a padding of 2.\n",
    "\n",
    "The main benefits of padding are the following:\n",
    "\n",
    "- It allows you to use a convolution layer without necessarily shrinking\n",
    "  the height and width of the volumes. This is important for building deeper\n",
    "  networks, since otherwise the height/width would shrink as you go to deeper\n",
    "  layers. An important special case is the \"same\" convolution, in which\n",
    "  the height/width is exactly preserved after one layer. \n",
    "- It helps us keep more of the information at the border of an image.\n",
    "  Without padding, very few values at the next layer would be affected\n",
    "  by pixels as the edges of an image.\n",
    "\n",
    "**Task**: Implement a function named `zero_pad()` which pads all the\n",
    "images of a batch of examples `X` with zeros.  \n",
    "\n",
    "The function takes the following input parameters:\n",
    "\n",
    "- `X` as input, a numpy array of shape `(m, height, width, channels)`\n",
    "  representing `m` samples of pictures with shape `(height, width, channels)`\n",
    "- Also it takes a second paramter `pad` which should default to 1, and is an intiger indicating\n",
    "the number of padding pixels around each image border.\n",
    "\n",
    "The function should be vectorized.  You probably want to use the\n",
    "numpy [np.pad](https://docs.scipy.org/doc/numpy/reference/generated/numpy.pad.html)\n",
    "function, which will do most of the work for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape:      (4, 3, 3, 3)\n",
      "X[0, :, :, 0]\n",
      "[[ 37  72 203]\n",
      " [192 204 252]\n",
      " [178 101 139]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### TESTED function zero_pad\n",
    "# uncomment when ready to run the unit tests for function, and uncomment below to test expected results\n",
    "#run_unittests(['test_zero_pad'])\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.randint(0, 256, size=(4, 3, 3, 3))\n",
    "#X_pad = zero_pad(X, 2)\n",
    "\n",
    "# expected shapes and padding\n",
    "print('X.shape:     ', X.shape)\n",
    "#print('X_pad.shape: ', X_pad.shape)\n",
    "print('X[0, :, :, 0]')\n",
    "print(X[0, :, :, 0])\n",
    "#print('X_pad[0, :, :, 0]')\n",
    "#print(X_pad[0, :, :, 0])\n",
    "\n",
    "# visualize expected padding\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(X[0, :, :, 0]);\n",
    "ax[0].set_title('X')\n",
    "ax[0].axis(False)\n",
    "#ax[1].imshow(X_pad[0, :, :, 0])\n",
    "ax[1].set_title('X_pad')\n",
    "ax[1].axis(False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: You should get:\n",
    "\n",
    "```\n",
    "X.shape:      (4, 3, 3, 3)\n",
    "X_pad.shape:  (4, 7, 7, 3)\n",
    "\n",
    "X[0, :, :, 0]\n",
    "[[ 37  72 203]\n",
    " [192 204 252]\n",
    " [178 101 139]]\n",
    " \n",
    "X_pad[0, :, :, 0]\n",
    "[[  0   0   0   0   0   0   0]\n",
    " [  0   0   0   0   0   0   0]\n",
    " [  0   0  37  72 203   0   0]\n",
    " [  0   0 192 204 252   0   0]\n",
    " [  0   0 178 101 139   0   0]\n",
    " [  0   0   0   0   0   0   0]\n",
    " [  0   0   0   0   0   0   0]]\n",
    "```\n",
    "\n",
    "And the small visualization should show black edges for your zero padding of\n",
    "pad width 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.2: Single Step of Convolution Operation\n",
    "\n",
    "In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which: \n",
    "\n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "\n",
    "<img src=\"../figures/single_step_convolution_animation.gif\" style=\"width:500px;height:300px;\">\n",
    "\n",
    "\n",
    "**Convolution operation**: with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide)\n",
    "\n",
    "**Note** The animation shows as if there is only a single channel, but in reality the\n",
    "input slice and window weights might have multiple channels of depth coming into this function.\n",
    "\n",
    "In a computer vision application, each value in the matrix on the left corresponds\n",
    "to a single pixel value, and we convolve a 3x3 filter with the image by \n",
    "**multiplying** its values **element-wise** with the original matrix,\n",
    "then **summing them up** and **adding a bias**. In this first step of\n",
    "the task, you will implement a single step of convolution,\n",
    "corresponding to applying a filter to just one of the positions to\n",
    "get a single real-valued output. \n",
    "\n",
    "Later in this notebook, you'll apply this function to multiple positions of the input to implement the full convolutional operation.\n",
    "\n",
    "**Task**: Declare and implement a function named `conv_single_step()`.  This\n",
    "function will take 3 input parameters:\n",
    "\n",
    "- `slice`: A slice of input data of shape (kernel_size, kernel_size, channels)\n",
    "- `W`: Weight parameters of the filter kernel, also of shape (kernel_size, kernel_size, channels)\n",
    "- `b`: Bias parameters of kernel filter, shape (1, 1, 1)\n",
    "\n",
    "Your function will return a single scalar value, which is the result of convolving\n",
    "the sliding window (W, b) on the slice of the input data.  This function should\n",
    "also be vectorized. \n",
    "\n",
    "**Hint**: you need to do an element wise multiplication, sum\n",
    "the result, and add the bias. \n",
    "\n",
    "**Hint**: we pass in the bias as a 3-D tensor with \n",
    "1 row, 1 column, 1 channel for a reason, but if you add a scalar to an array you\n",
    "will get an array, but your function must return a scalar value.  You should use\n",
    "the `.item()` member function in most recent NumPy version to convert an array of\n",
    "1 value to a scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 3)\n",
      "(4, 4, 3)\n",
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "### TESTED function conv_single_step\n",
    "# uncomment when ready to run the unit tests for function, and uncomment below to test expected results\n",
    "#run_unittests(['test_conv_single_step'])\n",
    "\n",
    "np.random.seed(1)\n",
    "slice = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "print(slice.shape)\n",
    "print(W.shape)\n",
    "print(b.shape)\n",
    "\n",
    "#c = conv_single_step(slice, W, b)\n",
    "#print('c = ', c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: The expected result with this random seed should be a single scalar\n",
    "floating point value:\n",
    "\n",
    "```\n",
    "(4, 4, 3)\n",
    "(4, 4, 3)\n",
    "(1, 1, 1)\n",
    "c =  -6.999089450680221\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.3: Convolution Forward Pass\n",
    "\n",
    "In the forward pass, you will take many filters and convolve them on\n",
    "the input.  Each 'convolution' gives you a 2D matrix output.  You\n",
    "will then stack these outputs to get a 3D volume:\n",
    "\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"../figures/convolution_animation.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n",
    "\n",
    "You are required to reuse your previous functions `calc_new_height_width()`\n",
    "and `zero_pad()` in this next task.  The `slice` will be taken by sliding over\n",
    "the input activation `A` into this function.  `W` and `b` are really the filter weights \n",
    "biases of the kernels for this convolution layer.  If you recall, in keras\n",
    "the parameter `filters=32` specifies the number of output\n",
    "filters/channels that are produced by a convolution layere.  So the final\n",
    "dimension of the `W` and `b` parameters are the number of output\n",
    "filters that the convolution produces.\n",
    "\n",
    "**Task**: Implement a function named `conv_forward()` to convolve the\n",
    "filters `W` / `b` on the input activation `A`.  The input parameters to this\n",
    "function are as follows:\n",
    "\n",
    "- `A`: The input activation into this convolution layer.  This is a numpy array of shape\n",
    "       `(m, height, width, channels_prev)`.  There will be `m` samples that come\n",
    "       in, all of the same `height x width` and with some number of channels.\n",
    "- `W`: The kernel Weights, a numpy array of shape\n",
    "       `(kernel_size, kernel_size, channels_prev, channels)`.  The first 3\n",
    "       dimensions need to be convolved with the input activations.  Notice the\n",
    "       4th dimension.  If the number of output filters of this convolution is 32,\n",
    "       then the last dimension would be 32 here, and you can think of `W` then\n",
    "       as having 32 individual weight kernels of shape\n",
    "       `(kernel_size, kernel_size, channels_prev)`\n",
    "- `b`: The kernel biases, which will be shaped `(1, 1, 1, channels)`.  Basically\n",
    "       there is one bias for every output channel this convolution produces.\n",
    "- `stride`: The stride size, an integer, should default to 1.\n",
    "- `pad`: The padding size to use, defaults to 0 to indicate use no padding.\n",
    "  \n",
    "This function returns the calculated convolution output activation `Z` that results\n",
    "from convolving all `W`/`b` kernal parameters over the input activations `A`.  \n",
    "\n",
    "- `Z`: convolution output, will be of shape `(m, new_height, new_width, channels)`\n",
    "  You can of course determine the number of samples `m` from the input Activation first\n",
    "  dimension, and the number of output channels `channels` are the 4th dimension\n",
    "  size of both `W` and `b`.  The `new_height` and `new_width` of course depend on\n",
    "  the `stride` and `pad` values.\n",
    "\n",
    "**Algorithm Description**\n",
    "\n",
    "For this task you do not need to implement a vectorized solution.  It is possible to vectorize, but\n",
    "create a solution here using for loop iterations.\n",
    "\n",
    "The basic algoirthm to do this is as follows:\n",
    "\n",
    "1. Extract the number of samples `m` and the original input `height` and `width` from the\n",
    "   passed in input activations `A` shape.\n",
    "2. Also you need the `kernel_size` and the number of `new_channels` which you can get from the passed\n",
    "   in `W` kernel weights shape.\n",
    "3. Given that information and the `stride` and `pad` which are given as parameters, you have enough\n",
    "   information to reuse your `calc_new_height_width` to calculate what the output height and width\n",
    "   will be for this convolution on the input `height` `width` and given the `kernel_size`,\n",
    "   `stride` and `pad` being used.\n",
    "4. Create an empty or zero filled array, which you could call `Z` for example, that will be the\n",
    "   returned results from the convolution.  The returned convolutions should have shape\n",
    "   `(m, new_height, new_width, channels)`\n",
    "5. Reuse your `zero_pad` function to pad the input activations `A` as needed before beginning\n",
    "   your calculation of the convolutions.\n",
    "\n",
    "Then to implement this in an iterative fashion, you need a 4 deep nested loop doing:\n",
    "\n",
    "```python\n",
    "for s in range(m):\n",
    "    for h in range(new_height):\n",
    "        # you need to calculate the start and end for dimension 1 height slice\n",
    "        for w in range(new_width):\n",
    "            # you need to calculate the start and end for dimension 2 height slice\n",
    "            for c in range(channels):\n",
    "                # you need the window from A[s, hstart:hend, vstart:vend, :] to pool\n",
    "                # you need to also slice the weights and biases to get only channel c kernel\n",
    "                # calculate Z[s, h, w, c] here using your conv_single_step()\n",
    "\n",
    "```\n",
    "\n",
    "6. Return the resulting Z output activations as your result.\n",
    "\n",
    "This is similar to the previous pooling implementation, with minor changes.  But in the main\n",
    "loops of the function, you need to do the same calculations to get the sliding window\n",
    "slice indexes.  Note: one differenc, the slice of A needs all of the previous channels.  You are\n",
    "only slicing `W` and `b` by the current channel `c` being iterated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TESTED function conv_forward\n",
    "# uncomment when ready to run the unit tests for function, and uncomment below to test expected results\n",
    "#run_unittests(['test_conv_forward'])\n",
    "\n",
    "np.random.seed(1)\n",
    "# input activations have 10 samples, 5x7 shape, with 4 channels coming in\n",
    "A = np.random.randn(10,5,7,4)\n",
    "# the settings of the kernel W/b parameters.  This convolution creates\n",
    "# 8 channel/filter outputs. The kernel size is 3, and because\n",
    "# we use stride=2 pad=1 the new heightxwidth are 4x8\n",
    "W = np.random.randn(3,3,4,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "stride = 2\n",
    "pad = 1\n",
    "\n",
    "#Z = conv_forward(A, W, b, stride, pad)\n",
    "#print('Z.shape: ', Z.shape)\n",
    "#print('Z.mean:  ', np.mean(Z))\n",
    "#print('Z channel means: ', Z.mean(axis=0).mean(axis=0).mean(axis=0)) # this is mean of each 8 channels\n",
    "#print('Z channel maxs: ', Z.max(axis=0).max(axis=0).max(axis=0)) # this is max of each 8 channels\n",
    "#print('Z sample 3, channel 2:')\n",
    "#print(Z[3,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output** You should get the following results for this example\n",
    "when using the given random seed:\n",
    "\n",
    "```\n",
    "Z.shape:  (10, 3, 4, 8)\n",
    "Z.mean:   0.6923608807576933\n",
    "Z channel means:  [ 1.5086006  -0.1743384   2.68375965 -0.35835072  2.76845058 -1.12789915\n",
    " -0.41870826  0.65737275]\n",
    "Z channel maxs:  [11.12355835 23.48197533 19.73741108 10.69033276 19.89262537  9.97188609\n",
    " 13.00689405 12.78954327]\n",
    "Z sample 3, channel 2:\n",
    "[[ 4.54315363  6.3188805   9.48395578  1.95844304]\n",
    " [ 8.07643821  9.59542022 19.73741108 -1.3748106 ]\n",
    " [ 3.36457258  6.61941931  9.9232075   8.78183548]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on completing this assignment. You now understand the most important mechanisms for convolutional neural networks.\n",
    "Hopefully you rememberd to make commits after each of the task functions and have pushed them to your GitHub repository for grading. \n",
    "\n",
    "<font color='blue'>\n",
    "    \n",
    "**What to remember from this assignment:**\n",
    "\n",
    "- The sliding window / kernel for pooling and convolutions conceptually work in a similar way.\n",
    "- The resulting output shape for a pooling or convolution operation depends on the window kernel_size, and the stride\n",
    "  and padding settings.\n",
    "- While the pooling and convolution operations can be made much more efficient by vectorizing them, iterating over each sample,\n",
    "  height, width and channel and computing the window slice for that combination gives the essential idea of what happens in\n",
    "  a convolution or pooling operation.\n",
    "- The convolution operation is really just a elementwise multiplication of two volumes of equal shape with a bias added in.  The result is a\n",
    "  single scalar value.  This scalar represents the output for a particular sample, window slice, and channel number of the convolution.\n",
    "- We usually use max pooling, but can use average pooling or other ways to combine.  The pooling operation preserves channels, so is really\n",
    "  just a pool over a kernel window height x width"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
